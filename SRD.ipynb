{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition Of Digits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Function for converting Wav to MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2mfcc(file_path, max_len=8):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=16000)\n",
    "    amplitude = []\n",
    "    for i in wave:\n",
    "        if abs(i)>0.009:\n",
    "            amplitude.append(i)\n",
    "    mfcc = librosa.feature.mfcc(np.asarray(amplitude))\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mfccs = wav2mfcc('test/one.wav')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "fig, ax = plt.subplots()\n",
    "mfcc_data= np.swapaxes(mfccs, 0 ,1)\n",
    "cax = ax.imshow(mfccs, interpolation='nearest', cmap=cm.coolwarm, origin='lower')\n",
    "ax.set_title('MFCC')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('MFCC Coeficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving MFCC Data for Furture Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The saved data is in pickle file which is availbale in GItHub (Can Skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SPEECH TO IMAGE ......  (Optional)\n",
    "\n",
    "# data = []\n",
    "# label = []\n",
    "# files_name = ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "# for name in files_name:\n",
    "#     for i in glob.glob('Digit_data/'+name+'/*'):\n",
    "#         data.append(wav2mfcc(i))\n",
    "#         if name=='zero':\n",
    "#             label.append(0)\n",
    "#         elif name=='one':\n",
    "#             label.append(1)\n",
    "#         elif name=='two':\n",
    "#             label.append(2)\n",
    "#         elif name=='three':\n",
    "#             label.append(3)\n",
    "#         elif name=='four':\n",
    "#             label.append(4)\n",
    "#         elif name=='five':\n",
    "#             label.append(5)\n",
    "#         elif name=='six':\n",
    "#             label.append(6)\n",
    "#         elif name=='seven':\n",
    "#             label.append(7)\n",
    "#         elif name=='eight':\n",
    "#             label.append(8)\n",
    "#         elif name=='nine':\n",
    "#             label.append(9)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SPEECH TO IMAGE ......  2 (Data Generation)\n",
    "\n",
    "\n",
    "# with open(\"Data_.pkl\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(data, fp)\n",
    "with open(\"Data_.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    data_ = pickle.load(fp)\n",
    "# print(np.asarray(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SPEECH TO IMAGE ......  3 (Data Generation)\n",
    "\n",
    "\n",
    "# with open(\"Label.pkl\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(label, fp)\n",
    "with open(\"Label.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    labels = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.asarray(data_).reshape(3000,20,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,val_x,train_y,val_y = train_test_split(np.asarray(data1),labels,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700, 20, 8, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Preparation......\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "train_x = train_x.reshape((2700,20*8)).astype('float32')/255\n",
    "val_x = val_x.reshape((300,20*8)).astype('float32')/255\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(20,8,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(10,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 18, 6, 32)         320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 1, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               28800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 39,658\n",
      "Trainable params: 39,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/navaneeth/anaconda3/envs/VIAI/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2857: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/navaneeth/anaconda3/envs/VIAI/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "2700/2700 [==============================] - 2s 702us/step - loss: 2.0229 - acc: 0.3626 - val_loss: 1.1814 - val_acc: 0.6233\n",
      "Epoch 2/50\n",
      "2700/2700 [==============================] - 1s 293us/step - loss: 1.0207 - acc: 0.6481 - val_loss: 0.7892 - val_acc: 0.7333\n",
      "Epoch 3/50\n",
      "2700/2700 [==============================] - 1s 251us/step - loss: 0.7276 - acc: 0.7519 - val_loss: 0.6773 - val_acc: 0.7900\n",
      "Epoch 4/50\n",
      "2700/2700 [==============================] - 1s 244us/step - loss: 0.5941 - acc: 0.7881 - val_loss: 0.5767 - val_acc: 0.8067\n",
      "Epoch 5/50\n",
      "2700/2700 [==============================] - 1s 234us/step - loss: 0.5056 - acc: 0.8222 - val_loss: 0.5441 - val_acc: 0.8200\n",
      "Epoch 6/50\n",
      "2700/2700 [==============================] - 1s 229us/step - loss: 0.4740 - acc: 0.8341 - val_loss: 0.4997 - val_acc: 0.8500\n",
      "Epoch 7/50\n",
      "2700/2700 [==============================] - 1s 260us/step - loss: 0.4015 - acc: 0.8615 - val_loss: 0.4934 - val_acc: 0.8500\n",
      "Epoch 8/50\n",
      "2700/2700 [==============================] - 1s 308us/step - loss: 0.3656 - acc: 0.8711 - val_loss: 0.4937 - val_acc: 0.8700\n",
      "Epoch 9/50\n",
      "2700/2700 [==============================] - 1s 232us/step - loss: 0.3358 - acc: 0.8800 - val_loss: 0.4494 - val_acc: 0.8633\n",
      "Epoch 10/50\n",
      "2700/2700 [==============================] - 1s 246us/step - loss: 0.3180 - acc: 0.8885 - val_loss: 0.4705 - val_acc: 0.8700\n",
      "Epoch 11/50\n",
      "2700/2700 [==============================] - 1s 234us/step - loss: 0.2822 - acc: 0.9033 - val_loss: 0.4389 - val_acc: 0.8900\n",
      "Epoch 12/50\n",
      "2700/2700 [==============================] - 1s 234us/step - loss: 0.2653 - acc: 0.9070 - val_loss: 0.4432 - val_acc: 0.8833\n",
      "Epoch 13/50\n",
      "2700/2700 [==============================] - 1s 256us/step - loss: 0.2549 - acc: 0.9107 - val_loss: 0.4182 - val_acc: 0.8867\n",
      "Epoch 14/50\n",
      "2700/2700 [==============================] - 1s 236us/step - loss: 0.2434 - acc: 0.9193 - val_loss: 0.4565 - val_acc: 0.8733\n",
      "Epoch 15/50\n",
      "2700/2700 [==============================] - 1s 241us/step - loss: 0.2281 - acc: 0.9178 - val_loss: 0.3998 - val_acc: 0.9067\n",
      "Epoch 16/50\n",
      "2700/2700 [==============================] - 1s 235us/step - loss: 0.2020 - acc: 0.9278 - val_loss: 0.4038 - val_acc: 0.9033\n",
      "Epoch 17/50\n",
      "2700/2700 [==============================] - 1s 232us/step - loss: 0.1903 - acc: 0.9337 - val_loss: 0.4399 - val_acc: 0.8833\n",
      "Epoch 18/50\n",
      "2700/2700 [==============================] - 1s 233us/step - loss: 0.1937 - acc: 0.9300 - val_loss: 0.3823 - val_acc: 0.8933\n",
      "Epoch 19/50\n",
      "2700/2700 [==============================] - 1s 234us/step - loss: 0.1793 - acc: 0.9393 - val_loss: 0.4747 - val_acc: 0.8867\n",
      "Epoch 20/50\n",
      "2700/2700 [==============================] - 1s 233us/step - loss: 0.1696 - acc: 0.9396 - val_loss: 0.3678 - val_acc: 0.9067\n",
      "Epoch 21/50\n",
      "2700/2700 [==============================] - 1s 238us/step - loss: 0.1587 - acc: 0.9441 - val_loss: 0.4011 - val_acc: 0.9000\n",
      "Epoch 22/50\n",
      "2700/2700 [==============================] - 1s 230us/step - loss: 0.1598 - acc: 0.9415 - val_loss: 0.4370 - val_acc: 0.9033\n",
      "Epoch 23/50\n",
      "2700/2700 [==============================] - 1s 234us/step - loss: 0.1435 - acc: 0.9485 - val_loss: 0.3857 - val_acc: 0.9133\n",
      "Epoch 24/50\n",
      "2700/2700 [==============================] - 1s 234us/step - loss: 0.1328 - acc: 0.9541 - val_loss: 0.4276 - val_acc: 0.9033\n",
      "Epoch 25/50\n",
      "2700/2700 [==============================] - 1s 234us/step - loss: 0.1582 - acc: 0.9441 - val_loss: 0.3924 - val_acc: 0.9033\n",
      "Epoch 26/50\n",
      "2700/2700 [==============================] - 1s 236us/step - loss: 0.1223 - acc: 0.9570 - val_loss: 0.4273 - val_acc: 0.8933\n",
      "Epoch 27/50\n",
      "2700/2700 [==============================] - 1s 236us/step - loss: 0.1186 - acc: 0.9574 - val_loss: 0.4166 - val_acc: 0.9067\n",
      "Epoch 28/50\n",
      "2700/2700 [==============================] - 1s 239us/step - loss: 0.1239 - acc: 0.9578 - val_loss: 0.4653 - val_acc: 0.9000\n",
      "Epoch 29/50\n",
      "2700/2700 [==============================] - 1s 241us/step - loss: 0.0978 - acc: 0.9693 - val_loss: 0.4344 - val_acc: 0.9033\n",
      "Epoch 30/50\n",
      "2700/2700 [==============================] - 1s 246us/step - loss: 0.0914 - acc: 0.9704 - val_loss: 0.4557 - val_acc: 0.8933\n",
      "Epoch 31/50\n",
      "2700/2700 [==============================] - 1s 239us/step - loss: 0.0896 - acc: 0.9715 - val_loss: 0.4826 - val_acc: 0.8867\n",
      "Epoch 32/50\n",
      "2700/2700 [==============================] - 1s 256us/step - loss: 0.1152 - acc: 0.9619 - val_loss: 0.5002 - val_acc: 0.8900\n",
      "Epoch 33/50\n",
      "2700/2700 [==============================] - 1s 239us/step - loss: 0.0929 - acc: 0.9711 - val_loss: 0.4845 - val_acc: 0.8933\n",
      "Epoch 34/50\n",
      "2700/2700 [==============================] - 1s 242us/step - loss: 0.0815 - acc: 0.9737 - val_loss: 0.4453 - val_acc: 0.9133\n",
      "Epoch 35/50\n",
      "2700/2700 [==============================] - 1s 236us/step - loss: 0.0774 - acc: 0.9744 - val_loss: 0.4916 - val_acc: 0.9000\n",
      "Epoch 36/50\n",
      "2700/2700 [==============================] - 1s 250us/step - loss: 0.0706 - acc: 0.9785 - val_loss: 0.4790 - val_acc: 0.9067\n",
      "Epoch 37/50\n",
      "2700/2700 [==============================] - 1s 247us/step - loss: 0.0729 - acc: 0.9756 - val_loss: 0.4540 - val_acc: 0.9233\n",
      "Epoch 38/50\n",
      "2700/2700 [==============================] - 1s 267us/step - loss: 0.0721 - acc: 0.9763 - val_loss: 0.5309 - val_acc: 0.9100\n",
      "Epoch 39/50\n",
      "2700/2700 [==============================] - 1s 355us/step - loss: 0.0648 - acc: 0.9785 - val_loss: 0.4702 - val_acc: 0.8933\n",
      "Epoch 40/50\n",
      "2700/2700 [==============================] - 1s 286us/step - loss: 0.0608 - acc: 0.9815 - val_loss: 0.4005 - val_acc: 0.9300\n",
      "Epoch 41/50\n",
      "2700/2700 [==============================] - 1s 257us/step - loss: 0.0675 - acc: 0.9781 - val_loss: 0.4834 - val_acc: 0.9233\n",
      "Epoch 42/50\n",
      "2700/2700 [==============================] - 1s 262us/step - loss: 0.0565 - acc: 0.9800 - val_loss: 0.5284 - val_acc: 0.9100\n",
      "Epoch 43/50\n",
      "2700/2700 [==============================] - 1s 263us/step - loss: 0.0541 - acc: 0.9807 - val_loss: 0.5182 - val_acc: 0.8767\n",
      "Epoch 44/50\n",
      "2700/2700 [==============================] - 1s 266us/step - loss: 0.0655 - acc: 0.9785 - val_loss: 0.4925 - val_acc: 0.9100\n",
      "Epoch 45/50\n",
      "2700/2700 [==============================] - 1s 256us/step - loss: 0.0548 - acc: 0.9837 - val_loss: 0.4378 - val_acc: 0.9067\n",
      "Epoch 46/50\n",
      "2700/2700 [==============================] - 1s 273us/step - loss: 0.0585 - acc: 0.9796 - val_loss: 0.5718 - val_acc: 0.8967\n",
      "Epoch 47/50\n",
      "2700/2700 [==============================] - 1s 267us/step - loss: 0.0698 - acc: 0.9770 - val_loss: 0.5483 - val_acc: 0.8967\n",
      "Epoch 48/50\n",
      "2700/2700 [==============================] - 1s 266us/step - loss: 0.0561 - acc: 0.9811 - val_loss: 0.5136 - val_acc: 0.9167\n",
      "Epoch 49/50\n",
      "2700/2700 [==============================] - 1s 262us/step - loss: 0.0593 - acc: 0.9815 - val_loss: 0.5119 - val_acc: 0.9067\n",
      "Epoch 50/50\n",
      "2700/2700 [==============================] - 1s 253us/step - loss: 0.0360 - acc: 0.9896 - val_loss: 0.4665 - val_acc: 0.9200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,train_y,epochs=50,batch_size=64,validation_data=(val_x,val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('SRD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('VIAI': conda)",
   "language": "python",
   "name": "python36964bitviaicondad67a75aa1a5a45afa108f3e07c66361d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
